mutate(booknumber = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
donhar_dtm <- donhar_words %>%
cast_dtm(booknumber, word, n)
tm::inspect(donhar_dtm)
donhar_words <- donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(author, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
donhar_dtm <- donhar_words %>%
cast_dtm(author, word, n)
tm::inspect(donhar_dtm)
donhar_lda <- LDA(donhar_dtm, k = 6, control = list(seed = 1234))
donhar_topics <- tidy(donhar_lda, matrix = "beta")
head(donhar_topics, n = 6)
donhar_top_terms <- donhar_topics %>%
group_by(topic) %>%
top_n(6, beta) %>%
ungroup() %>%
arrange(topic, -beta)
donhar_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free", ncol = 4) +
scale_y_reordered() +
theme_tufte(base_family = "Helvetica")
donhar_topics <- tidy(donhar_lda, matrix = "beta")
head(donhar_topics, n = 10)
donhar_top_terms <- donhar_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
donhar_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free", ncol = 4) +
scale_y_reordered() +
theme_tufte(base_family = "Helvetica")
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "blue", high = "green") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "blue", high = "green") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "blue", high = "blue") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkgray", high = "lightgray") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "lightgray", high = "darkgray") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
tidy_donhar <- donhar %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_donhar %>%
count(word, sort = TRUE)
bookfreq <- tidy_donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion)
ggplot(bookfreq, aes(x = Donovan, y = Hardy, color = abs(Donovan - Hardy))) +
geom_abline(color = "red", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "red") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Donovan", y = "Hardy") +
coord_equal()
donhar <- donhar %>%
filter(!is.na(text))
# Divide into documents, each representing one chapter
donhar_chapter <- donhar %>%
mutate(author = ifelse(gutenberg_id==53368, "Donovan", "Hardy")) %>%
group_by(author) %>%
mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, author, chapter)
# Split into words
donhar_chapter_word <- donhar_chapter %>%
unnest_tokens(word, text)
# Find document-word counts
donhar_word_counts <- donhar_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
donhar_word_counts
# Cast into DTM format for LDA analysis
donhar_chapters_dtm <- donhar_word_counts %>%
cast_dtm(document, word, n)
tm::inspect(donhar_chapters_dtm)
donhar_chapters_lda <- LDA(donhar_chapters_dtm, k = 2, control = list(seed = 1234))
View(donhar_chapters_lda)
donhar_chapters_gamma <- tidy(donhar_chapters_lda, matrix = "gamma")
donhar_chapters_gamma
View(assignments)
View(bookfreq)
View(tocq_words)
View(tocq_word_counts)
# First separate the document name into title and chapter
donhar_chapters_gamma <- donhar_chapters_gamma %>%
separate(document, c("title", "chapter"), sep = "_", convert = TRUE)
donhar_chapter_classifications <- donhar_chapters_gamma %>%
group_by(title, chapter) %>%
top_n(1, gamma) %>%
ungroup()
donhar_book_topics <- donhar_chapter_classifications %>%
count(title, topic) %>%
group_by(title) %>%
top_n(1, n) %>%
ungroup() %>%
transmute(consensus = title, topic)
donhar_chapter_classifications %>%
inner_join(donhar_book_topics, by = "topic") %>%
filter(title != consensus)
# Look document-word pairs were to see which words in each documents were assigned
# to a given topic
assignments <- augment(donhar_chapters_lda, data = donhar_chapters_dtm)
assignments
assignments <- assignments %>%
separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
inner_join(donhar_book_topics, by = c(".topic" = "topic"))
assignments %>%
count(title, consensus, wt = count) %>%
group_by(title) %>%
mutate(percent = n / sum(n)) %>%
ggplot(aes(consensus, title, fill = percent)) +
geom_tile() +
scale_fill_gradient2(high = "red", label = percent_format()) +
geom_text(aes(x = consensus, y = title, label = scales::percent(percent))) +
theme_tufte(base_family = "Helvetica") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
panel.grid = element_blank()) +
labs(x = "Book words assigned to",
y = "Book words came from",
fill = "% of assignments")
# First separate the document name into title and chapter
donhar_chapters_gamma <- donhar_chapters_gamma %>%
separate(document, c("title", "chapter"), sep = "_", convert = TRUE)
install.packages("topicmodels")
install.packages("quanteda")
install.packages("quanteda.textmodels")
install.packages("ggthemes")
install.packages("gutenbergr")
library(tidyverse) # loads dplyr, ggplot2, and others
library(stringr) # to handle text elements
library(tidytext) # includes set of functions useful for manipulating text
library(topicmodels) # to estimate topic models
library(gutenbergr) # to get text data
library(scales)
library(tm)
library(ggthemes) # to make your plots look nice
library(readr)
library(quanteda)
library(quanteda.textmodels)
install.packages(devtools)
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
install.packages("devtools")
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
library(tidyverse) # loads dplyr, ggplot2, and others
library(stringr) # to handle text elements
library(tidytext) # includes set of functions useful for manipulating text
library(topicmodels) # to estimate topic models
library(gutenbergr) # to get text data
library(scales)
library(tm)
library(ggthemes) # to make your plots look nice
library(readr)
library(quanteda)
library(quanteda.textmodels)
install.packages("devtools")
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
library(tidyverse) # loads dplyr, ggplot2, and others
library(stringr) # to handle text elements
library(tidytext) # includes set of functions useful for manipulating text
library(topicmodels) # to estimate topic models
library(gutenbergr) # to get text data
library(scales)
library(tm)
library(ggthemes) # to make your plots look nice
library(readr)
library(quanteda)
library(quanteda.textmodels)
install.packages("devtools")
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
install.packages("gutenbergr")
library(gutenbergr) # to get text data
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>% ##mutate() creates new column in the  dataset
unnest_tokens(word, text) %>% ##splits column into tokens aka single words, here we're interested in words and texts (built-in options)
filter(!is.na(word)) %>% ##is.na indicated missing elements,filter retains the rows that satisfy the condition, ! expression means NOT -> filter by non-missing words
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% ##ungrouping the data
anti_join(stop_words) ##removinh stop words from dataset
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>%
anti_join(stop_words)
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>%
anti_join(stop_words)
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>%
anti_join(stop_words)
anti_join(stop_words)
library(dplyr)
anti_join(stop_words)
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>%
anti_join(stop_words)
library(preText)
install.packages("devtools")
install.packages("devtools")
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
library(devtools)
devtools::install_github("matthewjdenny/preText")
library(preText)
install.packages("devtools")
library(devtools)
devtools::install_github("matthewjdenny/preText")
library(preText)
vignette('getting_started_with_preText')
library(preText)
tocq <- gutenberg_download(c(815, 816),
meta_fields = "author")
